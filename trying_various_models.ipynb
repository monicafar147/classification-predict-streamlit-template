{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trying_various_models.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicafar147/classification-predict-streamlit-template/blob/Modeling/trying_various_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFQhYTWsgZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6852cdc9-75dd-4a59-e683-75dd886c491e"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.11)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.6/dist-packages (from comet-git-pure>=0.19.11->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP39xluOsk_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "81757a68-dd73-48f4-9383-081d354c0623"
      },
      "source": [
        "# import comet_ml in the top of your file\n",
        "from comet_ml import Experiment\n",
        "    \n",
        "# Add the following code anywhere in your machine learning file\n",
        "experiment = Experiment(api_key=\"rBqQ3hDuEa6xVpT9ns5Tz1dVt\",project_name=\"nlp-climate-change\", workspace=\"monicafar147\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/monicafar147/nlp-climate-change/ce2af673f20142018236c705c1bc7a88\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_e9WjyW7zRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "b817e6b4-73e1-48e1-be52-ebc9532f28ac"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-deep')\n",
        "\n",
        "# text preprocessing\n",
        "import re\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# models\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZY3j6fc7zZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/monicafar147/classification-predict-streamlit-template/master/climate-change-belief-analysis/train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/monicafar147/classification-predict-streamlit-template/master/climate-change-belief-analysis/test.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0PZTMaE7zcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "cd03dff0-008e-454b-aa87-348f7fca3c99"
      },
      "source": [
        "print(\"Train\\n\")\n",
        "print(train.head(5))\n",
        "print(\"\\nTest\")\n",
        "print(test.head(5))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "\n",
            "   sentiment                                            message  tweetid\n",
            "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
            "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
            "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
            "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
            "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954\n",
            "\n",
            "Test\n",
            "                                             message  tweetid\n",
            "0  Europe will now be looking to China to make su...   169760\n",
            "1  Combine this with the polling of staffers re c...    35326\n",
            "2  The scary, unimpeachable evidence that climate...   224985\n",
            "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
            "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59B5hNC7zfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(tweet):\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub(r\"\\W\", \" \", tweet)\n",
        "  tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) \n",
        "  tweet = word_tokenize(tweet)\n",
        "  stopwords_list = set(stopwords.words('english') + list(punctuation))\n",
        "  tweets = [word for word in tweet if word not in stopwords_list]\n",
        "  return \" \".join(tweet)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWK3_RMQ2EDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the labels and features\n",
        "train['processed'] = train['message'].apply(preprocess)\n",
        "X = train['processed']\n",
        "y = train['sentiment']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOgreYHI8acf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the labels and fetures into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxRIdIciNl9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "ffadc7c3-03db-4598-99cc-a3093ff05e96"
      },
      "source": [
        "# Decision tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "text_cls = Pipeline([('tfidf',TfidfVectorizer()),('classify',clf)])\n",
        "text_cls.fit(X_train, y_train)\n",
        "\n",
        "pred = text_cls.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report = print(classification_report(y_test, pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.28      0.21      0.24       126\n",
            "           0       0.35      0.34      0.35       224\n",
            "           1       0.70      0.72      0.71       895\n",
            "           2       0.56      0.58      0.57       337\n",
            "\n",
            "    accuracy                           0.60      1582\n",
            "   macro avg       0.47      0.47      0.47      1582\n",
            "weighted avg       0.59      0.60      0.59      1582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IukrgntuvWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionaries for the data we want to log\n",
        "\n",
        "params = {\"preprocessing\":  \"preprocess(data)\",\n",
        "          \"model_type\": \"DecisionTreeClassifier\",\n",
        "          \"test size\":\"0.1\"\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report,\n",
        "           }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET-j-S-eNmAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "dff70943-8062-4034-b500-15b71d369bd0"
      },
      "source": [
        "# Linear SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svc = LinearSVC()\n",
        "text_svc = Pipeline([('tfidf',TfidfVectorizer()),('classify',svc)])\n",
        "text_svc.fit(X_train, y_train)\n",
        "\n",
        "pred_2 = text_svc.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report_2 = print(classification_report(y_test, pred_2))\n",
        "report_2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.67      0.52      0.59       126\n",
            "           0       0.66      0.42      0.52       224\n",
            "           1       0.80      0.86      0.83       895\n",
            "           2       0.75      0.83      0.79       337\n",
            "\n",
            "    accuracy                           0.77      1582\n",
            "   macro avg       0.72      0.66      0.68      1582\n",
            "weighted avg       0.76      0.77      0.76      1582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOhxYBLfvA_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionaries for the data we want to log\n",
        "\n",
        "params = {\"preprocessing\":  \"preprocess(data)\",\n",
        "          \"model_type\": \"LinearSVC\",\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report_2,\n",
        "           }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ9TPzZb4LCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeA-ot4LNmC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gaussian not working though\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "naive_bayes = GaussianNB()\n",
        "text_nb = Pipeline([('tfidf',TfidfVectorizer()),('classify',naive_bayes)])\n",
        "XD_train = X_train.toarray()\n",
        "text_nb.fit(XD_train, y_train)\n",
        "\n",
        "pred_3 = text_nb.predict(X_test)\n",
        "report_3 = print(classification_report(y_test, pred_3))\n",
        "report_3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCJx2j2fRfas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "083abbca-5063-468f-9c0e-8d4ca8fb378b"
      },
      "source": [
        "# K nearest neighbours, 250 seems best but maybe could be a better option\n",
        "n_neighbors = 250\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "knn = KNeighborsClassifier(n_neighbors)\n",
        "text_knn = Pipeline([('tfidf',TfidfVectorizer()),('classify',knn)])\n",
        "text_knn.fit(X_train, y_train)\n",
        "\n",
        "pred_4 = text_knn.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report_4 = print(classification_report(y_test, pred_4))\n",
        "report_4\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.01      0.02       126\n",
            "           0       0.88      0.03      0.06       224\n",
            "           1       0.63      0.97      0.76       895\n",
            "           2       0.84      0.45      0.59       337\n",
            "\n",
            "    accuracy                           0.65      1582\n",
            "   macro avg       0.83      0.37      0.36      1582\n",
            "weighted avg       0.74      0.65      0.57      1582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-QkZ5-7vTYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\"preprocessing\":  \"_preprocess(data)\",\n",
        "          \"model_type\": \"KNeighborsClassifier\",\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report_4,\n",
        "           }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xrn0Zqxw51CL",
        "colab": {}
      },
      "source": [
        "# Log our parameters and results\n",
        "experiment.log_parameters(params)\n",
        "experiment.log_metric(\"report\",report_4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWsyTrEC69em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "eb5bb6a7-09c7-4645-98df-a9e8c4721d99"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/monicafar147/nlp-climate-change/9eaa9b8e6ab7479ab682ebc63d3fb16d\n",
            "COMET INFO:   Metrics:\n",
            "COMET INFO:     report : 1\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     classify_algorithm     : auto\n",
            "COMET INFO:     classify_leaf_size     : 30\n",
            "COMET INFO:     classify_metric        : minkowski\n",
            "COMET INFO:     classify_metric_params : 1\n",
            "COMET INFO:     classify_n_jobs        : 1\n",
            "COMET INFO:     classify_n_neighbors   : 250\n",
            "COMET INFO:     classify_p             : 2\n",
            "COMET INFO:     classify_weights       : uniform\n",
            "COMET INFO:     model_type             : KNeighborsClassifier\n",
            "COMET INFO:     preprocessing          : _preprocess(data)\n",
            "COMET INFO:     tfidf_analyzer         : word\n",
            "COMET INFO:     tfidf_binary           : 1\n",
            "COMET INFO:     tfidf_decode_error     : strict\n",
            "COMET INFO:     tfidf_dtype            : <class 'numpy.float64'>\n",
            "COMET INFO:     tfidf_encoding         : utf-8\n",
            "COMET INFO:     tfidf_input            : content\n",
            "COMET INFO:     tfidf_lowercase        : True\n",
            "COMET INFO:     tfidf_max_df           : 1.0\n",
            "COMET INFO:     tfidf_max_features     : 1\n",
            "COMET INFO:     tfidf_min_df           : 1\n",
            "COMET INFO:     tfidf_ngram_range      : (1, 1)\n",
            "COMET INFO:     tfidf_norm             : l2\n",
            "COMET INFO:     tfidf_preprocessor     : 1\n",
            "COMET INFO:     tfidf_smooth_idf       : True\n",
            "COMET INFO:     tfidf_stop_words       : 1\n",
            "COMET INFO:     tfidf_strip_accents    : 1\n",
            "COMET INFO:     tfidf_sublinear_tf     : 1\n",
            "COMET INFO:     tfidf_token_pattern    : (?u)\\b\\w\\w+\\b\n",
            "COMET INFO:     tfidf_tokenizer        : 1\n",
            "COMET INFO:     tfidf_use_idf          : True\n",
            "COMET INFO:     tfidf_vocabulary       : 1\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (3 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfHGJX87Rfd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "9e60d4d8-a3fc-43f6-e316-d106c42f190d"
      },
      "source": [
        "# MulitnomialNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "text_mnb = Pipeline([('tfidf',TfidfVectorizer()),('classify',model)])\n",
        "text_mnb.fit(X_train, y_train)\n",
        "pred_5 = text_mnb.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report_5 = print(classification_report(y_test, pred_5))\n",
        "report_5\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       126\n",
            "           0       1.00      0.03      0.05       224\n",
            "           1       0.61      0.99      0.76       895\n",
            "           2       0.93      0.33      0.49       337\n",
            "\n",
            "    accuracy                           0.64      1582\n",
            "   macro avg       0.63      0.34      0.32      1582\n",
            "weighted avg       0.68      0.64      0.54      1582\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQzgO9wveSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\"preprocessing\":  \"_preprocess(data)\",\n",
        "          \"model_type\": \"MultinomialNB\",\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report_5,\n",
        "           }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdo97JqO4KYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Log our parameters and results\n",
        "experiment.log_parameters(params)\n",
        "experiment.log_metric(\"report\",report_5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQVxkyMi51CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "d6ab5e49-5dee-4cef-d76b-b58210a9eab5"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/monicafar147/nlp-climate-change/0123d48d967841669705fa90ac40a214\n",
            "COMET INFO:   Metrics:\n",
            "COMET INFO:     report : 1\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     alpha                : 1.0\n",
            "COMET INFO:     class_prior          : 1\n",
            "COMET INFO:     classify_alpha       : 1.0\n",
            "COMET INFO:     classify_class_prior : 1\n",
            "COMET INFO:     classify_fit_prior   : True\n",
            "COMET INFO:     fit_prior            : True\n",
            "COMET INFO:     model_type           : MultinomialNB\n",
            "COMET INFO:     preprocessing        : _preprocess(data)\n",
            "COMET INFO:     tfidf_analyzer       : word\n",
            "COMET INFO:     tfidf_binary         : 1\n",
            "COMET INFO:     tfidf_decode_error   : strict\n",
            "COMET INFO:     tfidf_dtype          : <class 'numpy.float64'>\n",
            "COMET INFO:     tfidf_encoding       : utf-8\n",
            "COMET INFO:     tfidf_input          : content\n",
            "COMET INFO:     tfidf_lowercase      : True\n",
            "COMET INFO:     tfidf_max_df         : 1.0\n",
            "COMET INFO:     tfidf_max_features   : 1\n",
            "COMET INFO:     tfidf_min_df         : 1\n",
            "COMET INFO:     tfidf_ngram_range    : (1, 1)\n",
            "COMET INFO:     tfidf_norm           : l2\n",
            "COMET INFO:     tfidf_preprocessor   : 1\n",
            "COMET INFO:     tfidf_smooth_idf     : True\n",
            "COMET INFO:     tfidf_stop_words     : 1\n",
            "COMET INFO:     tfidf_strip_accents  : 1\n",
            "COMET INFO:     tfidf_sublinear_tf   : 1\n",
            "COMET INFO:     tfidf_token_pattern  : (?u)\\b\\w\\w+\\b\n",
            "COMET INFO:     tfidf_tokenizer      : 1\n",
            "COMET INFO:     tfidf_use_idf        : True\n",
            "COMET INFO:     tfidf_vocabulary     : 1\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (2 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd8G4pI1RfhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "bb320f05-ccce-4f78-9a9b-f38df8affb28"
      },
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "text_lr = Pipeline([('tfidf',TfidfVectorizer()),('classify',lr)])\n",
        "text_lr.fit(X_train, y_train)\n",
        "pred_6 = text_lr.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "report_6 = print(classification_report(y_test, pred_6))\n",
        "report_6"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.75      0.31      0.44       126\n",
            "           0       0.67      0.34      0.45       224\n",
            "           1       0.76      0.88      0.82       895\n",
            "           2       0.74      0.80      0.77       337\n",
            "\n",
            "    accuracy                           0.75      1582\n",
            "   macro avg       0.73      0.59      0.62      1582\n",
            "weighted avg       0.74      0.75      0.72      1582\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "sklearn.linear_model._logistic:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb8Hj24wvmRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\"preprocessing\":  \"_preprocess(data)\",\n",
        "          \"model_type\": \"LogisticRegression\",\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report_6,\n",
        "           }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D3TExVWp7rn8",
        "colab": {}
      },
      "source": [
        "# Log our parameters and results\n",
        "experiment.log_parameters(params)\n",
        "experiment.log_metric(\"report\",report_6)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2qIRV4LQ7roE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f97ac9fa-ed1e-4c52-db28-1e8b01e45942"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/monicafar147/nlp-climate-change/ce2af673f20142018236c705c1bc7a88\n",
            "COMET INFO:   Metrics:\n",
            "COMET INFO:     report : 1\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     C                          : 1.0\n",
            "COMET INFO:     class_weight               : 1\n",
            "COMET INFO:     classify_C                 : 1.0\n",
            "COMET INFO:     classify_class_weight      : 1\n",
            "COMET INFO:     classify_dual              : 1\n",
            "COMET INFO:     classify_fit_intercept     : True\n",
            "COMET INFO:     classify_intercept_scaling : 1\n",
            "COMET INFO:     classify_l1_ratio          : 1\n",
            "COMET INFO:     classify_max_iter          : 100\n",
            "COMET INFO:     classify_multi_class       : auto\n",
            "COMET INFO:     classify_n_jobs            : 1\n",
            "COMET INFO:     classify_penalty           : l2\n",
            "COMET INFO:     classify_random_state      : 1\n",
            "COMET INFO:     classify_solver            : lbfgs\n",
            "COMET INFO:     classify_tol               : 0.0001\n",
            "COMET INFO:     classify_verbose           : 1\n",
            "COMET INFO:     classify_warm_start        : 1\n",
            "COMET INFO:     dual                       : 1\n",
            "COMET INFO:     fit_intercept              : True\n",
            "COMET INFO:     intercept_scaling          : 1\n",
            "COMET INFO:     l1_ratio                   : 1\n",
            "COMET INFO:     max_iter                   : 100\n",
            "COMET INFO:     model_type                 : LogisticRegression\n",
            "COMET INFO:     multi_class                : auto\n",
            "COMET INFO:     n_jobs                     : 1\n",
            "COMET INFO:     penalty                    : l2\n",
            "COMET INFO:     preprocessing              : _preprocess(data)\n",
            "COMET INFO:     random_state               : 1\n",
            "COMET INFO:     solver                     : lbfgs\n",
            "COMET INFO:     tfidf_analyzer             : word\n",
            "COMET INFO:     tfidf_binary               : 1\n",
            "COMET INFO:     tfidf_decode_error         : strict\n",
            "COMET INFO:     tfidf_dtype                : <class 'numpy.float64'>\n",
            "COMET INFO:     tfidf_encoding             : utf-8\n",
            "COMET INFO:     tfidf_input                : content\n",
            "COMET INFO:     tfidf_lowercase            : True\n",
            "COMET INFO:     tfidf_max_df               : 1.0\n",
            "COMET INFO:     tfidf_max_features         : 1\n",
            "COMET INFO:     tfidf_min_df               : 1\n",
            "COMET INFO:     tfidf_ngram_range          : (1, 1)\n",
            "COMET INFO:     tfidf_norm                 : l2\n",
            "COMET INFO:     tfidf_preprocessor         : 1\n",
            "COMET INFO:     tfidf_smooth_idf           : True\n",
            "COMET INFO:     tfidf_stop_words           : 1\n",
            "COMET INFO:     tfidf_strip_accents        : 1\n",
            "COMET INFO:     tfidf_sublinear_tf         : 1\n",
            "COMET INFO:     tfidf_token_pattern        : (?u)\\b\\w\\w+\\b\n",
            "COMET INFO:     tfidf_tokenizer            : 1\n",
            "COMET INFO:     tfidf_use_idf              : True\n",
            "COMET INFO:     tfidf_vocabulary           : 1\n",
            "COMET INFO:     tol                        : 0.0001\n",
            "COMET INFO:     verbose                    : 1\n",
            "COMET INFO:     warm_start                 : 1\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (2 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taRm38dY7uZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}